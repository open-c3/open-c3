#!/usr/bin/env /data/Software/mydan/python3/bin/python3
# -*- coding: utf-8 -*-

import sys
import json

import threading
import boto3
import time


class ThreadSafeArray:
    def __init__(self):
        self._array = []
        self._lock = threading.Lock()

    def append(self, value):
        with self._lock:
            self._array.append(value)


# 并发处理所有存储桶的最大线程数
MAX_CONCURRENT_NUMBER = 20


class S3:
    def __init__(self, account, access_id, access_key, region):
        self.account = account
        self.access_id = access_id
        self.access_key = access_key
        self.filter_region = region
        self.client = self.create_client()

        self.record_sync_error = {
            "lock": threading.Lock(),
            "error": None
        }

    def create_client(self):
        region = "cn-north-1" if self.filter_region.startswith("cn") else "us-east-1"
        return boto3.client(
            "s3",
            aws_access_key_id=self.access_id,
            aws_secret_access_key=self.access_key,
            region_name=region
        )
    
    def update_sync_error(self, error):
        with self.record_sync_error["lock"]:
            self.record_sync_error["error"] = error

    def add_tag_info_to_bucket(self, array, bucket_info):
        try:
            bucketLocationResp = self.client.get_bucket_location(
                Bucket=bucket_info["Name"],
            )

            bucket_real_location = bucketLocationResp["LocationConstraint"]
            if bucket_real_location == self.filter_region:
                tags = self.list_tag(
                    self.access_id, self.access_key, bucket_real_location, bucket_info["Name"]
                )

                bucket = {
                    "UUID": f'{self.account}-{bucket_real_location}-{bucket_info["Name"]}',
                    "BucketName": bucket_info["Name"],
                    "CreationDate": bucket_info["CreationDate"],
                    "RegionId": bucket_real_location,
                    "Tags": tags,
                }
                array.append(bucket)
        except Exception as e:
            self.update_sync_error(e)

    def list_buckets(self):
        response = self.client.list_buckets()

        array = ThreadSafeArray()
        threads = []
        for bucket_info in response["Buckets"]:
            if threading.active_count() > MAX_CONCURRENT_NUMBER:
                time.sleep(0.3)

            t = threading.Thread(
                target=self.add_tag_info_to_bucket,
                args=(array, bucket_info),
            )
            threads.append(t)
            t.start()

        for t in threads:
            t.join()
        
        if self.record_sync_error["error"] is not None:
            raise RuntimeError(f"同步s3时出现错误. ak: {self.access_id}") from self.record_sync_error["error"]

        return array._array

    def list_tag(self, access_id, access_key, region, bucket_name):
        sys.path.append("/data/Software/mydan/Connector/lib/pp")
        from c3mc_cloud_aws_s3_get_tag import GetTag

        return GetTag(access_id, access_key, region, bucket_name).list_tag()

    def show(self):
        bucket_list = self.list_buckets()
        for bucket in bucket_list:
            print(json.dumps(bucket, default=str))


def main(account, access_id, access_key, region):
    S3(account, access_id, access_key, region).show()


if __name__ == "__main__":
    main(sys.argv[1], sys.argv[2], sys.argv[3], sys.argv[4])
